{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn.metrics\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "# To display youtube videos\n",
    "#from IPython.display import YouTubeVideo\n",
    "\n",
    "\n",
    "def set_seed(seed = 1234):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device available now:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"LHXXI4-IEns\", width=500, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STATICS ====\n",
    "n_inputs = 4\n",
    "n_neurons = 1\n",
    "# =================\n",
    "\n",
    "# RNN inputs\n",
    "input0 = torch.tensor([[0, 1, 2, 0], [3, 4, 5, 0], [6, 7, 8, 0], [9, 0, 1, 0]], dtype = torch.float)\n",
    "print('input time_0 shape:', input0.shape)\n",
    "\n",
    "input1 = torch.tensor([[9, 8, 7, 0], [3, 4, 5, 0], [6, 7, 8, 0], [9, 0, 1, 0]], dtype = torch.float)\n",
    "print('input time_1 shape:', input1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Neural Network\n",
    "class RNNVanilla(nn.Module):\n",
    "    # __init__: the function where we create the architecture\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        super(RNNVanilla, self).__init__()\n",
    "        \n",
    "        # Weights are random at first\n",
    "        # U contains connection weights for the inputs of the current time step\n",
    "        self.U = torch.randn(n_inputs, n_neurons) # for 1 neuron: size = 4 rows and 1 column\n",
    "        \n",
    "        # W contains connection weights for the outputs of the previous time step\n",
    "        self.W = torch.randn(n_neurons, n_neurons) # for 1 neuron: size = 1 row and 1 column\n",
    "        \n",
    "        # The bias\n",
    "        self.b = torch.zeros(1, n_neurons) # for 1 neuron: size = 1 row and 1 column\n",
    "    \n",
    "    # forward: function where we apply the architecture to the input\n",
    "    def forward(self, input0, input1):\n",
    "        # Computes two outputs, one for each time step (two overall).\n",
    "        self.output0 = torch.tanh(torch.mm(input0, self.U) + self.b)\n",
    "        \n",
    "        self.output1 = torch.tanh(torch.mm(self.output0, self.W) + torch.mm(input1, self.U) + self.b)\n",
    "        \n",
    "        return self.output0, self.output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "rnn_1_neuron = RNNVanilla(n_inputs, n_neurons)\n",
    "\n",
    "# Checking the output\n",
    "output0, output1 = rnn_1_neuron(input0, input1)\n",
    "print('output0:', output0, '\\n')\n",
    "print('output1:', output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "print('U:', rnn_1_neuron.U)\n",
    "print('W:', rnn_1_neuron.W)\n",
    "print('bias:', rnn_1_neuron.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STATICS ====\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "# =================\n",
    "\n",
    "# RNN inputs\n",
    "input0 = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]], dtype = torch.float)\n",
    "print('input time_0 shape:', input0.shape)\n",
    "\n",
    "input1 = torch.tensor([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]], dtype = torch.float)\n",
    "print('input time_1 shape:', input1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "rnn_n_neurons = RNNVanilla(n_inputs, n_neurons)\n",
    "\n",
    "# Checking the output\n",
    "output0, output1 = rnn_n_neurons(input0, input1)\n",
    "print('output0:', output0, '\\n')\n",
    "print('output1:', output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "print('U:', rnn_n_neurons.U)\n",
    "print('W:', rnn_n_neurons.W)\n",
    "print('bias:', rnn_n_neurons.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Customized transform (transforms to tensor, here you can normalize, perform Data Augmentation etc.)\n",
    "my_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download data\n",
    "mnist_train = torchvision.datasets.MNIST('data', train = True, download=True, transform=my_transform)\n",
    "mnist_test = torchvision.datasets.MNIST('data', train = False, download=True, transform=my_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# The Neural Network\n",
    "class VanillaRNN_MNIST(nn.Module):\n",
    "    def __init__(self, batch_size, input_size, hidden_size, output_size):\n",
    "        super(VanillaRNN_MNIST, self).__init__()\n",
    "        self.batch_size, self.input_size, self.hidden_size, self.output_size = batch_size, input_size, hidden_size, output_size\n",
    "        \n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        # Fully Connected Layer\n",
    "        self.layer = nn.Linear(hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, images, prints=False):\n",
    "        if prints: print('Original Images Shape:', images.shape)\n",
    "        \n",
    "        images = images.permute(1, 0, 2)\n",
    "        if prints: print('Permuted Imaged Shape:', images.shape)\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        hidden_state = torch.zeros(1, self.batch_size, self.hidden_size)\n",
    "        if prints: print('Initial hidden state Shape:', hidden_state.shape)\n",
    "        \n",
    "        # Creating RNN\n",
    "        hidden_outputs, hidden_state = self.rnn(images, hidden_state)\n",
    "        \n",
    "        # Log probabilities\n",
    "        out = self.layer(hidden_state)\n",
    "        \n",
    "        if prints:\n",
    "            print('----hidden_outputs shape:', hidden_outputs.shape, '\\n' +\n",
    "                  '----final hidden state:', hidden_state.shape, '\\n' +\n",
    "                  '----out shape:', out.shape)\n",
    "        \n",
    "        # Reshaped out\n",
    "        out = out.view(-1, self.output_size)\n",
    "        if prints: print('Out Final Shape:', out.shape)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STATICS ====\n",
    "batch_size = 64        # how many images to be trained in one iteration\n",
    "input_size = 28        # image 28 by 28\n",
    "hidden_size = 150      # can be changed to any number: neurons\n",
    "output_size = 10       # 10 different digits\n",
    "# ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train_loader to select a batch from it\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=64)\n",
    "\n",
    "# Select one full batch from the data\n",
    "images_example, labels_example = next(iter(train_loader))\n",
    "print('original images shape:', images_example.shape)\n",
    "\n",
    "# Reshape\n",
    "images_example = images_example.view(-1, 28, 28)\n",
    "print('changed images shape:', images_example.shape)\n",
    "print('labels shape:', labels_example.shape, '\\n')\n",
    "\n",
    "# Creating the model\n",
    "model_example = VanillaRNN_MNIST(batch_size, input_size, hidden_size, output_size)\n",
    "\n",
    "\n",
    "out = model_example(images_example, prints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand Model Parameters\n",
    "print('Len parameters:', len(list(model_example.parameters())), '\\n' +\n",
    "      'Parameters 0 - U:', list(model_example.parameters())[0].shape, '\\n' +\n",
    "      'Parameters 1 - W:', list(model_example.parameters())[1].shape, '\\n' +\n",
    "      'Parameters 2 - Bias:', list(model_example.parameters())[2].shape, '\\n' +\n",
    "      'Parameters 3 - Bias:', list(model_example.parameters())[3].shape, '\\n' +\n",
    "      'Parameters 4 - FNN weights:', list(model_example.parameters())[4].shape, '\\n' +\n",
    "      'Parameters 5 - Predictions:', list(model_example.parameters())[5].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(out, actual_labels, batchSize):\n",
    "    '''Saves the Accuracy of the batch.\n",
    "    Takes in the log probabilities, actual label and the batchSize (to average the score).'''\n",
    "    predictions = out.max(dim=1)[1]\n",
    "    correct = (predictions == actual_labels).sum().item()\n",
    "    accuracy = correct/batch_size\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, train_data, test_data, batchSize=64, num_epochs=1, learning_rate=0.001):\n",
    "    \n",
    "    '''Trains the model and computes the average accuracy for train and test data.'''\n",
    "    \n",
    "    print('Get data ready...')\n",
    "    # Create dataloader for training dataset - so we can train on multiple batches\n",
    "    # Shuffle after every epoch\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batchSize, shuffle=True, drop_last=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batchSize, shuffle=True, drop_last=True)\n",
    "    \n",
    "    # Create criterion and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "    print('Training started...')\n",
    "    # Train the data multiple times\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Save Train and Test Loss\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        \n",
    "        # Set model in training mode:\n",
    "        model.train()\n",
    "        \n",
    "        for k, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # Get rid of the channel\n",
    "            images = images.view(-1, 28, 28)\n",
    "            \n",
    "            # Create log probabilities\n",
    "            out = model(images)\n",
    "            # Clears the gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            # Computes loss: how far is the prediction from the actual?\n",
    "            loss = criterion(out, labels)\n",
    "            # Computes gradients for neurons\n",
    "            loss.backward()\n",
    "            # Updates the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Save Loss & Accuracy after each iteration\n",
    "            train_loss += loss.item()\n",
    "            train_acc += get_accuracy(out, labels, batchSize)\n",
    "            \n",
    "        \n",
    "        # Print Average Train Loss & Accuracy after each epoch\n",
    "        print('TRAIN | Epoch: {}/{} | Loss: {:.2f} | Accuracy: {:.2f}'.format(epoch+1, num_epochs, train_loss/k, train_acc/k))\n",
    "            \n",
    "            \n",
    "    print('Testing Started...')\n",
    "    # Save Test Accuracy\n",
    "    test_acc = 0\n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    for k, (images, labels) in enumerate(test_loader):\n",
    "        # Get rid of the channel\n",
    "        images = images.view(-1, 28, 28)\n",
    "        \n",
    "        # Create logit predictions\n",
    "        out = model(images)\n",
    "        # Add Accuracy of this batch\n",
    "        test_acc += get_accuracy(out, labels, batchSize)\n",
    "        \n",
    "    # Print Final Test Accuracy\n",
    "    print('TEST | Average Accuracy per {} Loaders: {:.5f}'.format(k, test_acc/k) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STATICS ====\n",
    "batch_size=64\n",
    "input_size=28\n",
    "hidden_size=150\n",
    "output_size=10\n",
    "\n",
    "# Instantiate the model\n",
    "vanilla_rnn = VanillaRNN_MNIST(batch_size, input_size, hidden_size, output_size)\n",
    "\n",
    "# ==== TRAIN ====\n",
    "train_network(vanilla_rnn, mnist_train, mnist_test, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerRNN_MNIST(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, layer_size, output_size, relu=True):\n",
    "        super(MultilayerRNN_MNIST, self).__init__()\n",
    "        self.input_size, self.hidden_size, self.layer_size, self.output_size = input_size, hidden_size, layer_size, output_size\n",
    "        \n",
    "        # Create RNN\n",
    "        if relu:\n",
    "            self.rnn = nn.RNN(input_size, hidden_size, layer_size, batch_first=True, nonlinearity='relu')\n",
    "        else:\n",
    "            self.rnn = nn.RNN(input_size, hidden_size, layer_size, batch_first=True, nonlinearity='tanh')\n",
    "            \n",
    "        # Create FNN\n",
    "        self.fnn = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, images, prints=False):\n",
    "        if prints: print('images shape:', images.shape)\n",
    "        \n",
    "        # Instantiate hidden_state at timestamp 0\n",
    "        hidden_state = torch.zeros(self.layer_size, images.size(0), self.hidden_size)\n",
    "        hidden_state = hidden_state.requires_grad_()\n",
    "        if prints: print('Hidden State shape:', hidden_state.shape)\n",
    "        \n",
    "        # Compute RNN\n",
    "        # .detach() is required to prevent vanishing gradient problem\n",
    "        output, last_hidden_state = self.rnn(images, hidden_state.detach())\n",
    "        if prints: print('RNN Output shape:', output.shape, '\\n' +\n",
    "                         'RNN last_hidden_state shape', last_hidden_state.shape)\n",
    "        \n",
    "        # Compute FNN\n",
    "        # We get rid of the second size\n",
    "        output = self.fnn(output[:, -1, :])\n",
    "        if prints: print('FNN Output shape:', output.shape)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STATICS =====\n",
    "batch_size = 64\n",
    "input_size = 28\n",
    "hidden_size = 100      # neurons\n",
    "layer_size = 2         # layers\n",
    "output_size = 10\n",
    "# ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_example = torch.utils.data.DataLoader(mnist_train, batch_size=64)\n",
    "\n",
    "# Taking a single batch of the images\n",
    "images, labels = next(iter(train_loader_example))\n",
    "print('original images shape:', images.shape)\n",
    "\n",
    "# Remove channel from shape\n",
    "images = images.reshape(-1, 28, 28)\n",
    "print('reshaped images shape:', images.shape, '\\n')\n",
    "\n",
    "# Create model instance\n",
    "multilayer_rnn_example = MultilayerRNN_MNIST(input_size, hidden_size, layer_size, output_size, relu=False)\n",
    "print(multilayer_rnn_example)\n",
    "\n",
    "\n",
    "# Making log predictions:\n",
    "out = multilayer_rnn_example(images, prints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STATICS ====\n",
    "batch_size = 64\n",
    "input_size = 28\n",
    "hidden_size = 100  \n",
    "layer_size = 2         \n",
    "output_size = 10\n",
    "\n",
    "# Instantiate the model\n",
    "# We'll use TANH as our activation function\n",
    "multilayer_rnn = MultilayerRNN_MNIST(input_size, hidden_size, layer_size, output_size, relu=False)\n",
    "\n",
    "# ==== TRAIN ====\n",
    "train_network(multilayer_rnn, mnist_train, mnist_test, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"8HyCNIVRbSU\", width=500, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_MNIST(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, layer_size, output_size, bidirectional=True):\n",
    "        super(LSTM_MNIST, self).__init__()\n",
    "        \n",
    "        self.input_size, self.hidden_size, self.layer_size, self.output_size = input_size, hidden_size, layer_size, output_size\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        # Step1: the LSTM model\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, layer_size, batch_first=True, bidirectional=bidirectional)\n",
    "        \n",
    "        # Step2: the FNN\n",
    "        if bidirectional: # we'll have 2 more layers\n",
    "            self.layer = nn.Linear(hidden_size*2, output_size)\n",
    "        else:\n",
    "            self.layer = nn.Linear(hidden_size, output_size)\n",
    "            \n",
    "            \n",
    "    def forward(self, images, prints=False):\n",
    "        if prints: print('images shape:', images.shape)\n",
    "        \n",
    "        # Set initial states\n",
    "        if self.bidirectional:\n",
    "            # Hidden state:\n",
    "            hidden_state = torch.zeros(self.layer_size*2, images.size(0), self.hidden_size)\n",
    "            # Cell state:\n",
    "            cell_state = torch.zeros(self.layer_size*2, images.size(0), self.hidden_size)\n",
    "        else:\n",
    "            # Hidden state:\n",
    "            hidden_state = torch.zeros(self.layer_size, images.size(0), self.hidden_size)\n",
    "            # Cell state:\n",
    "            cell_state = torch.zeros(self.layer_size, images.size(0), self.hidden_size)\n",
    "        if prints: print('hidden_state t0 shape:', hidden_state.shape, '\\n' +\n",
    "                         'cell_state t0 shape:', cell_state.shape)\n",
    "        \n",
    "        # LSTM:\n",
    "        output, (last_hidden_state, last_cell_state) = self.lstm(images, (hidden_state, cell_state))\n",
    "        if prints: print('LSTM: output shape:', output.shape, '\\n' +\n",
    "                         'LSTM: last_hidden_state shape:', last_hidden_state.shape, '\\n' +\n",
    "                         'LSTM: last_cell_state shape:', last_cell_state.shape)\n",
    "        # Reshape\n",
    "        output = output[:, -1, :]\n",
    "        if prints: print('output reshape:', output.shape)\n",
    "        \n",
    "        # FNN:\n",
    "        output = self.layer(output)\n",
    "        if prints: print('FNN: Final output shape:', output.shape)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== STATICS ======\n",
    "batch_size = 64\n",
    "input_size = 28       # width of image\n",
    "hidden_size = 128     # number of hidden neurons\n",
    "layer_size = 2        # number of layers\n",
    "output_size = 10      # possible choices\n",
    "# ====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a single batch of the images\n",
    "images, labels = next(iter(train_loader_example))\n",
    "print('original images shape:', images.shape)\n",
    "# Remove channel from shape\n",
    "images = images.reshape(-1, 28, 28)\n",
    "print('reshaped images shape:', images.shape, '\\n')\n",
    "\n",
    "# Creating the Model\n",
    "lstm_example = LSTM_MNIST(input_size, hidden_size, layer_size, output_size)\n",
    "print('lstm_example:', lstm_example, '\\n')\n",
    "\n",
    "# Making log predictions:\n",
    "out = lstm_example(images, prints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STATICS ====\n",
    "batch_size = 64\n",
    "input_size = 28\n",
    "hidden_size = 100  \n",
    "layer_size = 2         \n",
    "output_size = 10\n",
    "\n",
    "# Instantiate the model\n",
    "# We'll use TANH as our activation function\n",
    "lstm_rnn = LSTM_MNIST(input_size, hidden_size, layer_size, output_size)\n",
    "\n",
    "# ==== TRAIN ====\n",
    "train_network(lstm_rnn, mnist_train, mnist_test, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(model, test_data):\n",
    "    # First we make sure we disable Gradient Computing\n",
    "    torch.no_grad()\n",
    "    \n",
    "    # Model in Evaluation Mode\n",
    "    model.eval()\n",
    "    \n",
    "    preds, actuals = [], []\n",
    "\n",
    "    for image, label in mnist_test:\n",
    "        image = image.view(-1, 28, 28)\n",
    "        out = model(image)\n",
    "\n",
    "        prediction = torch.max(out, dim=1)[1].item()\n",
    "        preds.append(prediction)\n",
    "        actuals.append(label)\n",
    "    \n",
    "    return sklearn.metrics.confusion_matrix(preds, actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "sns.heatmap(get_confusion_matrix(lstm_rnn, mnist_test), cmap='icefire', annot=True, linewidths=0.1,\n",
    "           fmt = ',')\n",
    "plt.title('Confusion Matrix: LSTM', fontsize=15);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
